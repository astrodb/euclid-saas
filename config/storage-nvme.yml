---
# This name is used for the Heat stack and as a prefix for the
# cluster node hostnames.
cluster_name: storage-nvme

# This parameter should be set to the name of an RSA keypair you have
# uplaoded to OpenStack.
cluster_keypair: bharat

# Site-specific network configuration.
cluster_net:
  - { net: "ilab", subnet: "ilab" }
  - { net: "p3-bdn", subnet: "p3-bdn" }
  - { net: "p3-lln", subnet: "p3-lln" }

# A 3-NIC node resource in the heat templates.
cluster_nodenet_environment: "nodenet-3.yaml"

# Enable the use of config drive, for managing IP assignment on IPoIB
cluster_config_drive: true

# Multi-node application topology.  In this case we have a SLURM
# deployment formed from a login/controller node and a number of
# batch compute nodes.
cluster_groups:
  - "{{ storage }}"

storage:
  name: "node"
  flavor: "storage-A"
  image: "CentOS7.5-OpenHPC"
  num_nodes: 1
  user: "centos"

# Node group assignments for cluster roles.
# These group assignments are appended to the cluster inventory file.
# The names of these roles are cross-referenced to groups referred to
# in playbooks in the ansible/ directory.
cluster_roles:
  - name: "mdadm"
    groups: [] #[ "{{ storage }}" ]
  - name: "glusterfs_server"
    groups: [ "{{ storage }}" ]
  - name: "glusterfs_client"
    groups: [ "{{ storage }}" ]
  - name: "beegfs_mgmt"
    groups: [ "{{ storage }}" ]
  - name: "beegfs_oss"
    groups: [ "{{ storage }}" ]
  - name: "beegfs_mds"
    groups: [ "{{ storage }}" ]
  - name: "beegfs_client"
    groups: ["{{ storage }}" ]

# Choose between glusterfs and beegfs
cluster_fs: beegfs

# Gluster config
gluster_cluster_volume_name: "{{ cluster_name }}"
gluster_cluster_block_devices:
- nvme0n1
- nvme1n1
- nvme2n1
- nvme3n1
gluster_cluster_transport_interface: ib0
gluster_cluster_transport_mode: rdma
gluster_cluster_force_format: no
gluster_cluster_volume_options:
  performance.cache-size: '10GB'
  diagnostics.brick-log-level: 'WARNING'

gluster_src: "localhost:/{{ gluster_cluster_volume_name }}"
gluster_mnt: "/mnt/{{ gluster_cluster_volume_name }}"

# BeegFS config
beegfs_state: present
beegfs_force_format: no
beegfs_interfaces:
- ib0
beegfs_mgmt_host: "{{ groups['cluster_beegfs_mgmt'] | first }}"
beegfs_oss_tunable:
- nvme0n1
- nvme1n1
- nvme2n1
- nvme3n1
beegfs_oss:
- dev: /dev/nvme0n1p1
  port: 8003
- dev: /dev/nvme0n1p2
  port: 8013
- dev: /dev/nvme1n1p1
  port: 8103
- dev: /dev/nvme1n1p2
  port: 8113
- dev: /dev/nvme2n1p1
  port: 8203
- dev: /dev/nvme2n1p2
  port: 8213
- dev: /dev/nvme3n1p1
  port: 8303
- dev: /dev/nvme3n1p2
  port: 8313
beegfs_client:
- path: "/mnt/{{ cluster_name }}"
  port: 18004

# Create more partitions so that there are more dedicated processes to handle incoming requests
partitions:
- dev: /dev/nvme0n1
  start: 0%
  end: 50%
  number: 1
- dev: /dev/nvme0n1
  start: 50%
  end: 100%
  number: 2
- dev: /dev/nvme1n1
  start: 0%
  end: 50%
  number: 1
- dev: /dev/nvme1n1
  start: 50%
  end: 100%
  number: 2
- dev: /dev/nvme2n1
  start: 0%
  end: 50%
  number: 1
- dev: /dev/nvme2n1
  start: 50%
  end: 100%
  number: 2
- dev: /dev/nvme3n1
  start: 0%
  end: 50%
  number: 1
- dev: /dev/nvme3n1
  start: 50%
  end: 100%
  number: 2

# Software defined raid config
md0:
  # Define array name
  name: 'md0'
  # Define disk devices to assign to array
  devices:
    - '/dev/nvme0n1'
    - '/dev/nvme2n1'
  # Define filesystem to partition array with
  filesystem: 'xfs'
  filesystem_opts: '-K'
  # Define the array raid level
  # 0|1|4|5|6|10
  level: '0'
  # Define if array should be present or absent
  state: 'present'

md1:
  # Define array name
  name: 'md1'
  # Define disk devices to assign to array
  devices:
    - '/dev/nvme1n1'
    - '/dev/nvme3n1'
  # Define filesystem to partition array with
  filesystem: 'xfs'
  filesystem_opts: '-K'
  # Define the array raid level
  # 0|1|4|5|6|10
  level: '0'
  # Define if array should be present or absent
  state: 'present'

mdadm_arrays:
  - "{{ md0 }}"
  - "{{ md1 }}"
...
